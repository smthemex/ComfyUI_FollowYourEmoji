# ComfyUI_FollowYourEmoji

You can using FollowYourEmoji in comfyui   
FollowYourEmojiï¼šFine-Controllable and Expressive Freestyle Portrait Animation  
--

FollowYourEmoji  From: [FollowYourEmoji](https://github.com/mayuelala/FollowYourEmoji/tree/main)
--

My ComfyUI node listï¼š
-----
1ã€ParlerTTS node:[ComfyUI_ParlerTTS](https://github.com/smthemex/ComfyUI_ParlerTTS)     
2ã€Llama3_8B node:[ComfyUI_Llama3_8B](https://github.com/smthemex/ComfyUI_Llama3_8B)      
3ã€HiDiffusion nodeï¼š[ComfyUI_HiDiffusion_Pro](https://github.com/smthemex/ComfyUI_HiDiffusion_Pro)   
4ã€ID_Animator nodeï¼š [ComfyUI_ID_Animator](https://github.com/smthemex/ComfyUI_ID_Animator)       
5ã€StoryDiffusion nodeï¼š[ComfyUI_StoryDiffusion](https://github.com/smthemex/ComfyUI_StoryDiffusion)  
6ã€Pops nodeï¼š[ComfyUI_Pops](https://github.com/smthemex/ComfyUI_Pops)   
7ã€stable-audio-open-1.0 node ï¼š[ComfyUI_StableAudio_Open](https://github.com/smthemex/ComfyUI_StableAudio_Open)        
8ã€GLM4 nodeï¼š[ComfyUI_ChatGLM_API](https://github.com/smthemex/ComfyUI_ChatGLM_API)   
9ã€CustomNet nodeï¼š[ComfyUI_CustomNet](https://github.com/smthemex/ComfyUI_CustomNet)           
10ã€Pipeline_Tool node :[ComfyUI_Pipeline_Tool](https://github.com/smthemex/ComfyUI_Pipeline_Tool)    
11ã€Pic2Story node :[ComfyUI_Pic2Story](https://github.com/smthemex/ComfyUI_Pic2Story)   
12ã€PBR_Maker node:[ComfyUI_PBR_Maker](https://github.com/smthemex/ComfyUI_PBR_Maker)      
13ã€ComfyUI_Streamv2v_Plus node:[ComfyUI_Streamv2v_Plus](https://github.com/smthemex/ComfyUI_Streamv2v_Plus)   
14ã€ComfyUI_MS_Diffusion node:[ComfyUI_MS_Diffusion](https://github.com/smthemex/ComfyUI_MS_Diffusion)   
15ã€ComfyUI_AnyDoor node: [ComfyUI_AnyDoor](https://github.com/smthemex/ComfyUI_AnyDoor)  
16ã€ComfyUI_Stable_Makeup node: [ComfyUI_Stable_Makeup](https://github.com/smthemex/ComfyUI_Stable_Makeup)  
17ã€ComfyUI_EchoMimic node:  [ComfyUI_EchoMimic](https://github.com/smthemex/ComfyUI_EchoMimic)   
18ã€ComfyUI_FollowYourEmoji node: [ComfyUI_FollowYourEmoji](https://github.com/smthemex/ComfyUI_FollowYourEmoji)   

Tipsï¼š
---
---é€‰æ‹©ä½ è¦å‚è€ƒçš„è¡¨æƒ…åŒ…è§†é¢‘ï¼Œé€‰æ‹©å‚è€ƒå›¾ç‰‡ï¼Œè¿è¡Œï¼›   
---åŸºäºå‚è€ƒè§†é¢‘ç”Ÿæˆçš„npyæ–‡ä»¶ï¼Œåœ¨input/emojiç›®å½•ä¸‹ï¼Œå†æ¬¡ä½¿ç”¨ï¼Œå¯ä»¥åœ¨â€œnpy_fileâ€èœå•ä¸­é€‰æ‹©ï¼ˆå¦‚æœä¸æ˜¾ç¤ºï¼Œé‡å¯comfyUIï¼‰   
---length ç”Ÿæˆè§†é¢‘æ—¶é•¿ï¼Œsave_video æ˜¯å¦ä¿å­˜æ–‡ä»¶ï¼›  
---â€œnpy_fileâ€ å’Œâ€œvideo_fileâ€é€‰é¡¹å‡ä¸æ˜¯noneæ—¶ï¼Œâ€œnpy_fileâ€ä¼˜å…ˆã€‚   
---Select the emoji video you want to reference, choose the reference image, and run it;   
---The npy file generated based on the reference video can be used again in the input/emoji directory by selecting it from the "npy_file" menu (if not displayed, restart comfyUI)ï¼›   
---Generate video duration using 'length', whether to save the file with 'save_video'ï¼›  
---When both the 'npy_file' and 'videoFILE' options are not 'none', 'npy_file' takes priority.   



1.Installation
-----
  In the ./ComfyUI /custom_node directory, run the following:   
```
git clone https://github.com/smthemex/ComfyUI_FollowYourEmoji.git
```  
  
2.requirements  
----
```
pip install -r requirements.txt

```
  
ç¼ºå•¥è£…å•¥ã€‚ã€‚ã€‚  
If the module is missing, , pip install  missing module.       

3 Need  model 
----
å¦‚æœèƒ½ç›´è¿æŠ±è„¸ï¼Œæˆ–è€…ç›´è¿é•œåƒç«™,ç‚¹å‡»å°±ä¼šè‡ªåŠ¨ä¸‹è½½æ‰€éœ€æ¨¡å‹,ä¸éœ€è¦å•ç‹¬ä¸‹è½½.   

unetä¸ComfyUI_EchoMimicçš„ä¸€æ ·  unet is the same as ComfyUI-EchoMimic    
unet [link](https://huggingface.co/lambdalabs/sd-image-variations-diffusers)  

image_encoder [link](https://huggingface.co/lambdalabs/sd-image-variations-diffusers)  

vae  stabilityai/sd-vae-ft-mse [link](https://huggingface.co/stabilityai/sd-vae-ft-mse/tree/main)

mm_sd_v15_v2.ckpt    [link](https://huggingface.co/guoyww/animatediff/tree/main)

main model  [link](https://huggingface.co/YueMafighting/FollowYourEmoji/tree/main/ckpts)   

æ‰€ç”¨æ¨¡å‹å­˜æ”¾åœ°å€ï¼ˆStorage address of the model usedï¼‰ï¼ˆall 14.1Gï¼‰:  
```
â”œâ”€â”€ ComfyUI/models/  
|     â”œâ”€â”€follow_emoji
|         â”œâ”€â”€ unet
|             â”œâ”€â”€ diffusion_pytorch_model.bin
|             â”œâ”€â”€ config.json
|         â”œâ”€â”€ image_encoder
|             â”œâ”€â”€ pytorch_model.bin
|             â”œâ”€â”€ config.json
|         â”œâ”€â”€ ckpts
|             â”œâ”€â”€ lmk_guider.pth
|             â”œâ”€â”€ referencenet.pth
|             â”œâ”€â”€ unet.pth
|         â”œâ”€â”€ mm_sd_v15_v2.ckpt
```




Example
-----
make emoji from video  ä»å‚è€ƒè§†é¢‘ç”Ÿæˆemoji       
![](https://github.com/smthemex/ComfyUI_FollowYourEmoji/blob/main/example/Animate.gif)



6 Citation   
If you find Follow-Your-Emoji useful for your research, welcome to ğŸŒŸ FollowYourEmoji repo and cite our work using the following BibTeX:
------
``` python  
@article{ma2024follow,
  title={Follow-Your-Emoji: Fine-Controllable and Expressive Freestyle Portrait Animation},
  author={Ma, Yue and Liu, Hongyu and Wang, Hongfa and Pan, Heng and He, Yingqing and Yuan, Junkun and Zeng, Ailing and Cai, Chengfei and Shum, Heung-Yeung and Liu, Wei and others},
  journal={arXiv preprint arXiv:2406.01900},
  year={2024}
}
```


